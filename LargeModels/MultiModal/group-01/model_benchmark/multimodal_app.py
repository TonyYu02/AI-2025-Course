# å¤šæ¨¡æ€å¤§æ¨¡å‹å‰ç«¯å±•ç¤ºä¸è¯„æµ‹ç³»ç»Ÿ ä¸ºåŒ—èˆªäººå·¥æ™ºèƒ½åŸç†å¤§ä½œä¸šè€Œåš Author:PXY ZRQ
import gradio as gr
import requests
import json
import base64
import time
from typing import Optional, Tuple, Dict, List
import io
from PIL import Image
import pandas as pd
import plotly.graph_objects as go


class BailianAPI:
    def __init__(self, api_key: str, base_url: str = "https://dashscope.aliyuncs.com"):
        self.api_key = api_key
        self.base_url = base_url
        self.model = "deepseek-r1-distill-qwen-7b"

        # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
        self.available_models = {
            "deepseek-r1-distill-qwen-7b": "DeepSeek R1 Distill Qwen 7B",
            "deepseek-r1-distill-qwen-14b": "DeepSeek R1 Distill Qwen 14B",
            "deepseek-r1-distill-qwen-32b": "DeepSeek R1 Distill Qwen 32B"
        }

    def encode_image_to_base64(self, image_path: str) -> str:
        """å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    def encode_pil_image_to_base64(self, pil_image: Image.Image) -> str:
        """å°†PILå›¾åƒå¯¹è±¡ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
        buffer = io.BytesIO()
        pil_image.save(buffer, format='PNG')
        img_str = base64.b64encode(buffer.getvalue()).decode('utf-8')
        return img_str

    def set_model(self, model_name: str):
        """è®¾ç½®å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
        if model_name in self.available_models:
            self.model = model_name
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")

    def call_api(self, messages: list, stream: bool = False) -> Tuple[str, float]:
        """è°ƒç”¨ç™¾ç‚¼å¹³å°APIï¼Œè¿”å›å“åº”å†…å®¹å’Œå“åº”æ—¶é—´"""
        url = f"{self.base_url}/compatible-mode/v1/chat/completions"

        payload = {
            "model": self.model,
            "stream": stream,
            "messages": messages
        }

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        try:
            start_time = time.time()
            response = requests.post(
                url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            end_time = time.time()
            response_time = end_time - start_time

            if stream:
                # å¤„ç†æµå¼å“åº”
                full_response = ""
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        if line_str.startswith('data: '):
                            data_str = line_str[6:]
                            if data_str.strip() == '[DONE]':
                                break
                            try:
                                data = json.loads(data_str)
                                if 'choices' in data and len(data['choices']) > 0:
                                    delta = data['choices'][0].get('delta', {})
                                    if 'content' in delta:
                                        full_response += delta['content']
                            except json.JSONDecodeError:
                                continue
                return full_response, response_time
            else:
                # å¤„ç†éæµå¼å“åº”
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    return result['choices'][0]['message']['content'], response_time
                else:
                    return "APIå“åº”æ ¼å¼é”™è¯¯", response_time

        except requests.exceptions.RequestException as e:
            return f"APIè°ƒç”¨é”™è¯¯: {str(e)}", 0.0
        except Exception as e:
            return f"å¤„ç†å“åº”æ—¶å‡ºé”™: {str(e)}", 0.0


def process_multimodal_input(text: str, image: Optional[Image.Image], api_key: str, model_name: str) -> str:
    """å¤„ç†å¤šæ¨¡æ€è¾“å…¥å¹¶è°ƒç”¨API"""
    if not text.strip() and image is None:
        return "è¯·è¾“å…¥æ–‡æœ¬æˆ–ä¸Šä¼ å›¾åƒ"

    if not api_key.strip():
        return "è¯·è¾“å…¥APIå¯†é’¥"

    # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
    api_client = BailianAPI(api_key)
    api_client.set_model(model_name)

    # æ„å»ºæ¶ˆæ¯
    messages = []
    content = []

    # æ·»åŠ æ–‡æœ¬å†…å®¹
    if text.strip():
        content.append({
            "type": "text",
            "text": text.strip()
        })

    # æ·»åŠ å›¾åƒå†…å®¹
    if image is not None:
        try:
            # å°†PILå›¾åƒè½¬æ¢ä¸ºbase64
            image_base64 = api_client.encode_pil_image_to_base64(image)
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_base64}"
                }
            })
        except Exception as e:
            return f"å›¾åƒå¤„ç†é”™è¯¯: {str(e)}"

    # æ„å»ºç”¨æˆ·æ¶ˆæ¯
    if content:
        messages.append({
            "role": "user",
            "content": content
        })

    # è°ƒç”¨API
    response, response_time = api_client.call_api(messages, stream=False)
    return f"{response}\n\nâ±ï¸ å“åº”æ—¶é—´: {response_time:.2f}ç§’"


def run_benchmark_test(api_key: str, test_prompts: List[str]) -> Dict:
    """è¿è¡Œæ¨ç†è¯„æµ‹ï¼Œæ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½"""
    if not api_key.strip():
        return {"error": "è¯·è¾“å…¥APIå¯†é’¥"}

    results = {}
    api_client = BailianAPI(api_key)

    for model_name in api_client.available_models.keys():
        api_client.set_model(model_name)
        model_results = {
            "model": api_client.available_models[model_name],
            "responses": [],
            "avg_response_time": 0,
            "stats": {},
            "response_lengths": []
        }

        times: List[float] = []
        for prompt in test_prompts:
            messages = [{"role": "user", "content": prompt}]
            response, response_time = api_client.call_api(
                messages, stream=False)

            model_results["responses"].append({
                "prompt": prompt,
                "response": response,
                "response_time": response_time
            })
            times.append(response_time)
            model_results["response_lengths"].append(
                len(response) if isinstance(response, str) else 0)

        s = pd.Series(times) if len(times) else pd.Series([0])
        model_results["avg_response_time"] = float(s.mean())
        model_results["stats"] = {
            "p50": float(s.quantile(0.5)),
            "p95": float(s.quantile(0.95)),
            "min": float(s.min()),
            "max": float(s.max()),
            "std": float(s.std(ddof=0)) if len(s) > 1 else 0.0,
            "avg_len": float(pd.Series(model_results["response_lengths"]).mean()) if model_results["response_lengths"] else 0.0
        }
        results[model_name] = model_results

    return results


def create_benchmark_results_table(results: Dict) -> str:
    """åˆ›å»ºè¯„æµ‹ç»“æœè¡¨æ ¼ï¼ˆç¾åŒ–æ ·å¼+æ›´å…¨é¢æŒ‡æ ‡ï¼‰"""
    if "error" in results:
        return results["error"]

    def perf_badge(v: float) -> str:
        return "<span style='color:#10B981'>ä¼˜ç§€</span>" if v < 2.0 else ("<span style='color:#F59E0B'>è‰¯å¥½</span>" if v < 5.0 else "<span style='color:#EF4444'>éœ€ä¼˜åŒ–</span>")

    rows_html = ""
    for _, data in results.items():
        rows_html += f"""
        <tr>
            <td class=\"cell-left\">{data['model']}</td>
            <td>{data['avg_response_time']:.2f}s</td>
            <td>{data['stats'].get('avg_len', 0):.0f}</td>
            <td>{perf_badge(data['avg_response_time'])}</td>
        </tr>
        """

    html = f"""
    <style>
      .perf-table {{
        width: 100%;
        border-collapse: separate;
        border-spacing: 0;
        margin: 12px 0;
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 2px 10px rgba(0,0,0,0.06);
      }}
      .perf-table thead tr {{
        background: linear-gradient(90deg, #EEF2FF 0%, #E0E7FF 100%);
      }}
      .perf-table th, .perf-table td {{
        padding: 10px 12px;
        border-bottom: 1px solid #E5E7EB;
        text-align: left;
        font-size: 14px;
      }}
      .perf-table th {{
        color: #111827;
        font-weight: 600;
      }}
      .perf-table tbody tr:nth-child(odd) {{
        background-color: #FAFAFF;
      }}
      .cell-left {{
        font-weight: 600;
        color: #374151;
      }}
    </style>
    <table class=\"perf-table\">
      <thead>
        <tr>
          <th>æ¨¡å‹</th>
          <th>å¹³å‡å“åº”æ—¶é—´</th>
          <th>å¹³å‡å›å¤é•¿åº¦</th>
          <th>æ€§èƒ½è¯„çº§</th>
        </tr>
      </thead>
      <tbody>
        {rows_html}
      </tbody>
    </table>
    """
    return html


def create_benchmark_bar_chart(results: Dict):
    """åˆ›å»ºæŸ±çŠ¶å›¾å¯¹æ¯”ï¼ˆä»…æ˜¾ç¤ºå‡å€¼ï¼‰"""
    if "error" in results:
        return go.Figure()

    models = [data["model"] for _, data in results.items()]
    avg = [data["avg_response_time"] for _, data in results.items()]

    fig = go.Figure()
    fig.add_bar(x=models, y=avg, name="å¹³å‡å“åº”æ—¶é—´", marker_color="#6366F1")
    fig.update_layout(
        height=380,
        margin=dict(l=10, r=10, t=30, b=10),
        title_text="æ¨¡å‹å¹³å‡å“åº”æ—¶é—´å¯¹æ¯”",
        yaxis_title="ç§’",
        xaxis_title="æ¨¡å‹",
        plot_bgcolor="#ffffff",
        paper_bgcolor="#ffffff"
    )
    return fig


def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="å¤šæ¨¡æ€å¤§æ¨¡å‹å±•ç¤ºä¸è¯„æµ‹", theme=gr.themes.Soft()) as interface:
        gr.Markdown("""
        # ğŸ¤– å¤šæ¨¡æ€å¤§æ¨¡å‹å±•ç¤ºä¸è¯„æµ‹ç³»ç»Ÿ
        
        åŸºäºç™¾ç‚¼å¹³å°APIçš„DeepSeek R1 Distill Qwenç³»åˆ—æ¨¡å‹å¤šæ¨¡æ€å¯¹è¯ä¸æ€§èƒ½è¯„æµ‹ç³»ç»Ÿ
        
        **åŠŸèƒ½ç‰¹ç‚¹ï¼š**
        - ğŸ“ æ”¯æŒæ–‡æœ¬è¾“å…¥å’Œå›¾åƒåˆ†æ
        - ğŸ”„ ä¸‰ç§æ¨¡å‹è‡ªç”±åˆ‡æ¢ (7B/14B/32B)
        - ğŸ“Š æ¨ç†æ€§èƒ½è¯„æµ‹å¯¹æ¯”
        - â±ï¸ å®æ—¶å“åº”æ—¶é—´ç›‘æ§
        """)

        # åˆ›å»ºæ ‡ç­¾é¡µ
        with gr.Tabs():
            # å¯¹è¯æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ’¬ å¤šæ¨¡æ€å¯¹è¯"):
                with gr.Row():
                    with gr.Column(scale=1):
                        # APIå¯†é’¥è¾“å…¥
                        api_key_input = gr.Textbox(
                            label="APIå¯†é’¥",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„ç™¾ç‚¼å¹³å°APIå¯†é’¥",
                            type="password",
                            value=""
                        )

                        # æ¨¡å‹é€‰æ‹©
                        model_selector = gr.Dropdown(
                            choices=[
                                ("DeepSeek R1 Distill Qwen 7B",
                                 "deepseek-r1-distill-qwen-7b"),
                                ("DeepSeek R1 Distill Qwen 14B",
                                 "deepseek-r1-distill-qwen-14b"),
                                ("DeepSeek R1 Distill Qwen 32B",
                                 "deepseek-r1-distill-qwen-32b")
                            ],
                            value="deepseek-r1-distill-qwen-7b",
                            label="é€‰æ‹©æ¨¡å‹",
                            info="é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹"
                        )

                        # æ–‡æœ¬è¾“å…¥
                        text_input = gr.Textbox(
                            label="æ–‡æœ¬è¾“å…¥",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æè¿°...",
                            lines=4
                        )

                        # å›¾åƒä¸Šä¼ 
                        image_input = gr.Image(
                            label="å›¾åƒä¸Šä¼ ",
                            type="pil",
                            height=300
                        )

                        # æäº¤æŒ‰é’®
                        submit_btn = gr.Button(
                            "å‘é€", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        # è¾“å‡ºåŒºåŸŸ
                        output_text = gr.Textbox(
                            label="æ¨¡å‹å›å¤",
                            lines=15,
                            interactive=False,
                            show_copy_button=True
                        )

            # è¯„æµ‹æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ“Š æ€§èƒ½è¯„æµ‹"):
                with gr.Row():
                    with gr.Column(scale=1):
                        # è¯„æµ‹APIå¯†é’¥
                        benchmark_api_key = gr.Textbox(
                            label="APIå¯†é’¥",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„ç™¾ç‚¼å¹³å°APIå¯†é’¥",
                            type="password",
                            value=""
                        )

                        # è¯„æµ‹ä»»åŠ¡é€‰æ‹©
                        benchmark_tasks = gr.CheckboxGroup(
                            choices=[
                                "æ•°å­¦æ¨ç†: 9.9å’Œ9.11è°å¤§ï¼Ÿ",
                                "é€»è¾‘æ¨ç†: è§£é‡Šä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹",
                                "åˆ›æ„å†™ä½œ: å¸®æˆ‘å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
                                "å¸¸è¯†é—®ç­”: ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
                                "ä»£ç ç”Ÿæˆ: å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"
                            ],
                            value=["æ•°å­¦æ¨ç†: 9.9å’Œ9.11è°å¤§ï¼Ÿ", "é€»è¾‘æ¨ç†: è§£é‡Šä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹"],
                            label="é€‰æ‹©è¯„æµ‹ä»»åŠ¡",
                            info="é€‰æ‹©è¦è¯„æµ‹çš„ä»»åŠ¡ç±»å‹"
                        )

                        # å¼€å§‹è¯„æµ‹æŒ‰é’®
                        benchmark_btn = gr.Button(
                            "å¼€å§‹è¯„æµ‹", variant="secondary", size="lg")

                        # è¯„çº§æ ‡å‡†è¯´æ˜
                        gr.Markdown("""
                        ### ğŸ“Š æ€§èƒ½è¯„çº§æ ‡å‡†
                        
                        - **ğŸŸ¢ ä¼˜ç§€**: å¹³å‡å“åº”æ—¶é—´ < 2ç§’
                        - **ğŸŸ¡ è‰¯å¥½**: å¹³å‡å“åº”æ—¶é—´ 2-5ç§’  
                        - **ğŸ”´ éœ€ä¼˜åŒ–**: å¹³å‡å“åº”æ—¶é—´ > 5ç§’
                        """)

                    with gr.Column(scale=2):
                        # è¯„æµ‹ç»“æœ
                        benchmark_chart = gr.Plot(label="å¹³å‡å“åº”æ—¶é—´å¯¹æ¯”å›¾")
                        benchmark_results = gr.HTML(
                            label="è¯„æµ‹ç»“æœ",
                            value="<p>ç‚¹å‡»'å¼€å§‹è¯„æµ‹'æŒ‰é’®å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•</p>"
                        )

        # ç¤ºä¾‹
        gr.Markdown("""
        ### ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹
        
        **å¯¹è¯åŠŸèƒ½ï¼š**
        - é€‰æ‹©ä¸åŒè§„æ¨¡çš„æ¨¡å‹è¿›è¡Œå¯¹è¯
        - æ”¯æŒæ–‡æœ¬å’Œå›¾åƒå¤šæ¨¡æ€è¾“å…¥
        - å®æ—¶æ˜¾ç¤ºå“åº”æ—¶é—´
        
        **è¯„æµ‹åŠŸèƒ½ï¼š**
        - é€‰æ‹©å¤šä¸ªä»»åŠ¡è¿›è¡Œæ€§èƒ½å¯¹æ¯”
        - è‡ªåŠ¨æµ‹è¯•ä¸‰ç§æ¨¡å‹çš„å“åº”æ—¶é—´
        - ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
        """)

        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            fn=process_multimodal_input,
            inputs=[text_input, image_input, api_key_input, model_selector],
            outputs=output_text
        )

        # å›è½¦é”®æäº¤
        text_input.submit(
            fn=process_multimodal_input,
            inputs=[text_input, image_input, api_key_input, model_selector],
            outputs=output_text
        )

        # è¯„æµ‹åŠŸèƒ½
        def run_benchmark(api_key, selected_tasks):
            if not selected_tasks:
                return None, "<p style='color: red;'>è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè¯„æµ‹ä»»åŠ¡</p>"

            # æå–ä»»åŠ¡æ–‡æœ¬
            test_prompts = []
            for task in selected_tasks:
                if ":" in task:
                    prompt = task.split(":", 1)[1].strip()
                    test_prompts.append(prompt)
                else:
                    test_prompts.append(task)

            # è¿è¡Œè¯„æµ‹
            results = run_benchmark_test(api_key, test_prompts)

            # ç”Ÿæˆç»“æœå›¾è¡¨ä¸è¡¨æ ¼
            chart = create_benchmark_bar_chart(results)
            table_html = create_benchmark_results_table(results)

            # æ·»åŠ è¯¦ç»†ç»“æœ
            detailed_results = "<h3>ğŸ“Š è¯¦ç»†è¯„æµ‹ç»“æœ</h3>"
            for model_name, data in results.items():
                if model_name != "error":
                    detailed_results += f"<h4>{data['model']}</h4>"
                    detailed_results += "<ul>"
                    for i, result in enumerate(data["responses"]):
                        detailed_results += f"""
                        <li>
                            <strong>ä»»åŠ¡ {i+1}:</strong> {result['prompt']}<br>
                            <strong>å“åº”æ—¶é—´:</strong> {result['response_time']:.2f}ç§’<br>
                            <strong>å›å¤:</strong> {result['response'][:100]}...
                        </li>
                        """
                    detailed_results += "</ul>"

            return chart, table_html + detailed_results

        benchmark_btn.click(
            fn=run_benchmark,
            inputs=[benchmark_api_key, benchmark_tasks],
            outputs=[benchmark_chart, benchmark_results]
        )

    return interface


if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    app = create_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
